{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91847748",
      "metadata": {},
      "source": [
        "# Cap√≠tulo extra ‚Äî EM para repartir contribuciones de MMM a campa√±as/creatividades (MTA)\n",
        "\n",
        "## 0) Qu√© es observado y qu√© es latente\n",
        "\n",
        "### Observado (sale del MMM)\n",
        "\n",
        "Tienes para cada periodo (y opcionalmente geo):\n",
        "\n",
        "* ($t \\in {1,\\dots,T}$) (semana/d√≠a)\n",
        "* ($g \\in {1,\\dots,G}$) (geo) opcional\n",
        "\n",
        "Y del MMM obtienes contribuciones por canal/medio:\n",
        "\n",
        "* ($C_{m,t}$) o ($C_{m,t,g}$): contribuci√≥n del **medio/canal** (m) en ese corte.\n",
        "\n",
        "> Nota: esto puede ser ‚Äúincremental contribution‚Äù del MMM o ‚Äúattributed contribution‚Äù seg√∫n el modelo. EM solo lo toma como ‚Äútotal a repartir‚Äù.\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "Repartir esa contribuci√≥n de cada medio (m) hacia unidades inferiores:\n",
        "\n",
        "* campa√±as (k), creatividades, adsets, publishers‚Ä¶ (lo que definas)\n",
        "\n",
        "### Latente\n",
        "\n",
        "* ($z_{m,k,t}$) (o ($z_{m,k,t,g}$)): contribuci√≥n del medio (m) en (t) asignada a campa√±a/crea (k)\n",
        "\n",
        "Restricci√≥n dura:\n",
        "\n",
        "$$\n",
        "\\sum_{k\\in \\mathcal{K}*m} z*{m,k,t} = C_{m,t}\n",
        "\\quad (\\text{o } \\sum_k z_{m,k,t,g}=C_{m,t,g})\n",
        "$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a3463d",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 1) Modelo generativo base (an√°logamente al HCP‚ÄìBrick)\n",
        "\n",
        "La analog√≠a es directa:\n",
        "\n",
        "| HCP‚ÄìBrick            | MMM‚ÜíMTA                                                   |\n",
        "| -------------------- | --------------------------------------------------------- |\n",
        "| Brick                | (medio (m), tiempo (t), geo (g))                          |\n",
        "| HCP                  | campa√±a/creatividad (k) dentro del medio                  |\n",
        "| ventas (y_b)         | contribuci√≥n (C_{m,t,g})                                  |\n",
        "| exposici√≥n (w_{h,b}) | se√±ales a nivel campa√±a: spend, impressions, clicks, etc. |\n",
        "\n",
        "### Exposici√≥n / evidencia por campa√±a\n",
        "\n",
        "Define features o exposici√≥n para cada campa√±a:\n",
        "\n",
        "* (w_{m,k,t,g}) = spend (o impresiones) de la campa√±a (k) del medio (m) en (t,g)\n",
        "* y opcionalmente features (X_{m,k}) (tipo campa√±a, objetivo, formato‚Ä¶)\n",
        "\n",
        "### Productividad latente por campa√±a dentro del medio\n",
        "\n",
        "Caso simple (sin covariables a√∫n):\n",
        "\n",
        "* (\\lambda_{m,k} > 0) (tasa/productividad relativa de campa√±a (k) dentro de medio (m))\n",
        "\n",
        "Modelo Poisson (para ‚Äúunidades de contribuci√≥n‚Äù):\n",
        "[\n",
        "z_{m,k,t,g} \\sim \\text{Poisson}(\\lambda_{m,k}, w_{m,k,t,g})\n",
        "]\n",
        "y observamos:\n",
        "[\n",
        "C_{m,t,g}=\\sum_k z_{m,k,t,g}\n",
        "]\n",
        "\n",
        "Si (C) es continua (euros), puedes usar Gamma (m√°s abajo).\n",
        "\n",
        "---\n",
        "\n",
        "## 2) EM expl√≠cito en este contexto (soluci√≥n)\n",
        "\n",
        "### E-step: repartir (C_{m,t,g}) dentro de cada (m,t,g)\n",
        "\n",
        "Define:\n",
        "[\n",
        "\\mu_{m,k,t,g}^{(r)} = \\lambda_{m,k}^{(r)}, w_{m,k,t,g}\n",
        "]\n",
        "[\n",
        "p_{m,k,t,g}^{(r)}=\n",
        "\\frac{\\mu_{m,k,t,g}^{(r)}}{\\sum_{k'}\\mu_{m,k',t,g}^{(r)}}\n",
        "]\n",
        "\n",
        "Entonces:\n",
        "[\n",
        "\\boxed{\n",
        "\\mathbb{E}[z_{m,k,t,g}\\mid C_{m,t,g},\\lambda^{(r)}] = C_{m,t,g} \\cdot p_{m,k,t,g}^{(r)}\n",
        "}\n",
        "]\n",
        "\n",
        "Interpretaci√≥n:\n",
        "\n",
        "* dentro de cada medio-tiempo-geo, la campa√±a se lleva m√°s contribuci√≥n si tiene:\n",
        "\n",
        "  * m√°s exposici√≥n (w) y/o\n",
        "  * m√°s productividad (\\lambda).\n",
        "\n",
        "### M-step: actualizar (\\lambda_{m,k})\n",
        "\n",
        "Acumulas:\n",
        "[\n",
        "\\tilde z_{m,k}=\\sum_{t,g}\\mathbb{E}[z_{m,k,t,g}]\n",
        "\\quad,\\quad\n",
        "\\tilde w_{m,k}=\\sum_{t,g} w_{m,k,t,g}\n",
        "]\n",
        "\n",
        "MLE tipo Poisson:\n",
        "[\n",
        "\\boxed{\n",
        "\\lambda_{m,k}^{(r+1)} = \\frac{\\tilde z_{m,k}}{\\tilde w_{m,k}}\n",
        "}\n",
        "]\n",
        "\n",
        "Eso ya es EM completo (sin covariables).\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Versi√≥n ‚Äúrealista‚Äù: covariables + regularizaci√≥n\n",
        "\n",
        "Como antes:\n",
        "[\n",
        "\\lambda_{m,k}=\\exp(X_{m,k}\\beta_m)\n",
        "]\n",
        "\n",
        "* (\\beta_m) puede ser por medio, o compartido\n",
        "\n",
        "M-step se vuelve un **Poisson GLM con offset**:\n",
        "\n",
        "* response: (\\tilde z_{m,k})\n",
        "* offset: (\\log \\tilde w_{m,k})\n",
        "* regularizaci√≥n ridge/lasso para estabilidad\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Caso euros (contribuciones continuas)\n",
        "\n",
        "Si (C_{m,t,g}) es continua (moneda), Gamma suele funcionar bien:\n",
        "\n",
        "[\n",
        "z_{m,k,t,g} \\sim \\text{Gamma}(k,\\ \\theta_{m,k} w_{m,k,t,g})\n",
        "]\n",
        "con (\\theta_{m,k}=\\exp(X\\beta))\n",
        "\n",
        "En muchas parametrizaciones razonables, el reparto del E-step queda (muy similar):\n",
        "[\n",
        "\\mathbb{E}[z_{m,k,t,g}\\mid C_{m,t,g}]\n",
        "\\approx\n",
        "C_{m,t,g}\\cdot\n",
        "\\frac{\\theta_{m,k} w_{m,k,t,g}}{\\sum_{k'}\\theta_{m,k'} w_{m,k',t,g}}\n",
        "]\n",
        "y el M-step es Gamma-GLM (log link) + regularizaci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Qu√© est√°s aprendiendo realmente (y l√≠mites)\n",
        "\n",
        "Este EM aprende **productividad relativa intra-medio** de campa√±as/creas **consistente con**:\n",
        "\n",
        "* la serie temporal (y geo) de contribuci√≥n total del MMM\n",
        "* el patr√≥n de exposici√≥n de campa√±as (spend/imp/clicks)\n",
        "\n",
        "**No** est√° recuperando ‚Äúverdad causal por campa√±a‚Äù si:\n",
        "\n",
        "* el MMM no est√° bien identificado por canal\n",
        "* hay campa√±as altamente colineales dentro del medio\n",
        "* falta se√±al (w) (o est√° muy ruidosa)\n",
        "\n",
        "Pero como ‚Äúdesagregador coherente‚Äù del MMM, funciona muy bien.\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Lo de ‚Äúgranularidad horaria‚Äù en MTA (para m√°s adelante)\n",
        "\n",
        "Tu comentario es clave: MMM suele estar en semanal/d√≠a; MTA a veces se quiere a hora/minuto.\n",
        "\n",
        "Hay 3 rutas t√≠picas:\n",
        "\n",
        "1. **Downscaling con modelo de intensidad**\n",
        "   Aprendes un ‚Äúperfil intrad√≠a‚Äù (q(h \\mid k,g)) con logs de delivery (imp/click/spend horario) y repartes:\n",
        "   [\n",
        "   z_{m,k,t,g,h} = z_{m,k,t,g}\\cdot q(h\\mid k,g)\n",
        "   ]\n",
        "   Esto es determinista o con EM a dos niveles.\n",
        "\n",
        "2. **Estado-espacio / smoothing temporal**\n",
        "   Tratas (\\lambda_{m,k,t}) como proceso (random walk) y haces inferencia (Kalman/VI).\n",
        "   √ötil si quieres que productividades var√≠en por hora.\n",
        "\n",
        "3. **Modelo unificado a alta frecuencia**\n",
        "   Solo si tienes outcomes y gasto a esa frecuencia (caro y con mucho ruido).\n",
        "\n",
        "---\n",
        "\n",
        "# Ejercicio propuesto (con soluci√≥n)\n",
        "\n",
        "**Ejercicio:** Implementa EM para un solo medio (m) con:\n",
        "\n",
        "* (C_t) semanal\n",
        "* campa√±as (k=1..K)\n",
        "* exposici√≥n (w_{k,t}) = spend\n",
        "  y estima (\\lambda_k) + (z_{k,t}).\n",
        "\n",
        "**Soluci√≥n:** las ecuaciones de arriba (E-step/M-step) y luego extender a covariables con GLM.\n",
        "\n",
        "---\n",
        "\n",
        "## ¬øQuieres que lo aterricemos ya en c√≥digo?\n",
        "\n",
        "Puedo darte un notebook muy parecido al del HCP‚ÄìBrick pero con:\n",
        "\n",
        "* input: `C_{m,t,g}` (del MMM) + `w_{m,k,t,g}` (spend/imp/click)\n",
        "* output: `zhat_{m,k,t,g}` y productividades por campa√±a\n",
        "\n",
        "Y con dos modos:\n",
        "\n",
        "* ‚Äúsin covariables‚Äù (updates cerrados)\n",
        "* ‚Äúcon covariables‚Äù (M-step con IRLS + ridge)\n",
        "\n",
        "Si lo hacemos, asumir√© por defecto:\n",
        "\n",
        "* contribuci√≥n (C) continua pero **no negativa**\n",
        "* exposici√≥n = spend (>=0), con smoothing cuando hay ceros\n",
        "\n",
        "Dime solo si quieres que empecemos por:\n",
        "\n",
        "1. **1 medio, sin geo** (m√°s simple), o\n",
        "2. **1 medio, con geo**, o\n",
        "3. **multi-medio** (mismo framework, un loop por medio).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f36914",
      "metadata": {},
      "source": [
        "Genial: si quieres usar **impresiones/GRPs** y adem√°s respetar **adstock + saturaci√≥n** (como en MMM), eso cambia el ‚Äúqu√© significa exposici√≥n‚Äù en el EM, pero el framework encaja muy bien.\n",
        "\n",
        "Voy por tus 2 preguntas.\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Si el MMM es incremental (causal), ¬øel reparto MTA tambi√©n lo es?\n",
        "\n",
        "**Depende de qu√© entiendas por ‚Äúcausal‚Äù a nivel campa√±a**, pero la respuesta operativa es:\n",
        "\n",
        "* **El total que repartes (por canal/medio y por (t), (g)) s√≠ es incremental/causal** *si tu MMM lo es*.\n",
        "* **El reparto dentro del canal (campa√±as/creas)** **no es autom√°ticamente causal** a menos que tengas **identificaci√≥n causal intra-canal**.\n",
        "\n",
        "### Por qu√©\n",
        "\n",
        "El MMM ‚Äúincremental‚Äù te identifica algo como:\n",
        "[\n",
        "C_{m,t,g}^{inc} = f(\\text{inputs del canal }m) - f(\\text{contrafactual sin canal }m)\n",
        "]\n",
        "Eso es causal a nivel canal (bajo supuestos).\n",
        "\n",
        "Pero cuando lo repartes entre campa√±as, normalmente est√°s usando:\n",
        "\n",
        "* se√±ales de delivery (impresiones/GRPs, targeting, timing)\n",
        "* y un modelo de ‚Äúpropensi√≥n‚Äù / ‚Äúintensidad‚Äù\n",
        "  para decidir shares.\n",
        "\n",
        "Eso da una atribuci√≥n **coherente** con el incremental del canal, pero **no demuestra** que ‚Äúesa campa√±a‚Äù sea incremental vs otra, porque dentro del canal puede haber:\n",
        "\n",
        "* colinealidad fuerte (campa√±as corren a la vez)\n",
        "* selecci√≥n/endogeneidad (las campa√±as se activan cuando se espera demanda)\n",
        "* distinta mezcla de audiencias\n",
        "\n",
        "### C√≥mo s√≠ hacerlo ‚Äúm√°s causal‚Äù intra-canal\n",
        "\n",
        "Necesitar√≠as se√±al de identificaci√≥n adicional, por ejemplo:\n",
        "\n",
        "* experimentos / geo-lift por campa√±a\n",
        "* cambios ex√≥genos (holdouts, rotaciones creativas, shocks de supply)\n",
        "* instrumentos o reglas de asignaci√≥n\n",
        "* o un modelo jer√°rquico que incorpore ‚Äúpriors causales‚Äù basados en pruebas\n",
        "\n",
        "üìå Conclusi√≥n clara:\n",
        "\n",
        "> **MTA por EM puede conservar el ‚Äúincremental total‚Äù del MMM**, pero el **split intra-canal es principalmente model-based attribution**, no causal garantizado.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) C√≥mo insertar adstock + saturaci√≥n en la soluci√≥n EM (con impresiones/GRPs)\n",
        "\n",
        "La forma limpia es: **no usar exposici√≥n cruda (w)**, sino la **exposici√≥n efectiva** tal y como MMM la usa para generar contribuci√≥n.\n",
        "\n",
        "### En MMM t√≠pico\n",
        "\n",
        "Para una subentidad (k) (campa√±a/crea) del canal (m), tienes una se√±al ‚Äúraw‚Äù:\n",
        "\n",
        "* (x_{m,k,t,g}): impresiones / GRPs / TRPs (no spend)\n",
        "\n",
        "MMM aplica transformaciones:\n",
        "\n",
        "1. **Adstock** (carryover):\n",
        "   [\n",
        "   a_{m,k,t,g} = \\text{Adstock}(x_{m,k,\\cdot,g}; \\theta_m)\n",
        "   ]\n",
        "   (p. ej. geom√©trico con decay (\\theta_m), o Weibull)\n",
        "\n",
        "2. **Saturaci√≥n** (rendimientos decrecientes):\n",
        "   [\n",
        "   s_{m,k,t,g} = \\text{Sat}(a_{m,k,t,g}; \\phi_m)\n",
        "   ]\n",
        "   (p. ej. Hill / logistic)\n",
        "\n",
        "Y la contribuci√≥n incremental del canal suele ser algo como:\n",
        "[\n",
        "C_{m,t,g}^{inc} \\approx \\beta_m \\sum_k s_{m,k,t,g}\n",
        "]\n",
        "(si el MMM no tiene campa√±as expl√≠citas, esto es una descomposici√≥n plausible)\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥mo meter esto en EM (dos opciones)\n",
        "\n",
        "#### ‚úÖ Opci√≥n A (recomendada): EM reparte usando **exposici√≥n efectiva MMM-consistente**\n",
        "\n",
        "Define la exposici√≥n del EM como:\n",
        "[\n",
        "w_{m,k,t,g} := s_{m,k,t,g}\n",
        "]\n",
        "(es decir, **ya adstockeada y saturada**)\n",
        "\n",
        "Entonces el E-step (shares) queda:\n",
        "[\n",
        "\\hat z_{m,k,t,g} = C_{m,t,g}^{inc}\\cdot\n",
        "\\frac{\\lambda_{m,k} \\cdot s_{m,k,t,g}}\n",
        "{\\sum_{k'} \\lambda_{m,k'} \\cdot s_{m,k',t,g}}\n",
        "]\n",
        "\n",
        "Ventajas:\n",
        "\n",
        "* Mantienes exactamente la l√≥gica MMM (carryover + diminishing returns)\n",
        "* Evitas atribuir m√°s a campa√±as solo por impresiones brutas si est√°n saturadas\n",
        "* Muy estable y f√°cil de explicar\n",
        "\n",
        "Qu√© se aprende:\n",
        "\n",
        "* (\\lambda_{m,k}) = ‚Äúeficiencia relativa‚Äù intra-canal (sobre se√±al efectiva)\n",
        "\n",
        "D√≥nde pones par√°metros de adstock/sat:\n",
        "\n",
        "* Los tomas del MMM (fijos) o los fijas por canal.\n",
        "\n",
        "#### Opci√≥n B: EM tambi√©n aprende algunos par√°metros de transformaci√≥n\n",
        "\n",
        "Puedes extender par√°metros (\\theta_m,\\phi_m) al set de par√°metros y alternar:\n",
        "\n",
        "* E-step: imputar (z)\n",
        "* M-step: actualizar (\\beta) y quiz√°s (\\theta,\\phi)\n",
        "\n",
        "Pero aqu√≠ hay un problema pr√°ctico:\n",
        "\n",
        "* adstock/saturaci√≥n + shares suelen estar **muy no convexos**\n",
        "* identificabilidad d√©bil (especialmente intra-canal)\n",
        "* entrenamiento m√°s fr√°gil (necesitar√≠as constraints/priors fuertes)\n",
        "\n",
        "üìå Para empezar y para producci√≥n, casi siempre:\n",
        "\n",
        "> **usar (\\theta_m,\\phi_m) del MMM (fijos) y aprender solo el reparto intra-canal**.\n",
        "\n",
        "---\n",
        "\n",
        "### ¬øY si el MMM est√° a nivel canal y no tienes series por campa√±a?\n",
        "\n",
        "Entonces haces ‚Äútop-down‚Äù:\n",
        "\n",
        "* Construyes (s_{m,k,t,g}) a partir de delivery de campa√±a (imps/GRPs) usando los mismos (\\theta_m,\\phi_m)\n",
        "* Y repartes (C_{m,t,g}^{inc}) con la f√≥rmula anterior\n",
        "\n",
        "Esto es exactamente lo que quieres.\n",
        "\n",
        "---\n",
        "\n",
        "## Recomendaci√≥n final antes del notebook (sin pedirte datos extra)\n",
        "\n",
        "Para el notebook te propongo este dise√±o:\n",
        "\n",
        "* Inputs mock:\n",
        "\n",
        "  * (C_{t}) o (C_{t,g}): contrib incremental por canal (observado)\n",
        "  * (x_{k,t,g}): impresiones/GRPs por campa√±a (observado)\n",
        "* Transformaciones:\n",
        "\n",
        "  * adstock geom√©trico por canal\n",
        "  * saturaci√≥n Hill por canal\n",
        "* EM:\n",
        "\n",
        "  * E-step usando (w=s(x))\n",
        "  * M-step estimando (\\lambda_k) (cerrado) o (\\lambda_k=\\exp(X_k\\beta)) (GLM)\n",
        "\n",
        "Y a√±adimos secci√≥n ‚Äúm√°s adelante‚Äù:\n",
        "\n",
        "* desagregaci√≥n a horas via perfil intrad√≠a usando delivery horario + conservaci√≥n de masa\n",
        "\n",
        "---\n",
        "\n",
        "## Checkpoint\n",
        "\n",
        "Si est√°s OK con esto:\n",
        "\n",
        "* **El total es causal (del MMM), el split intra-canal es attribution model-based**.\n",
        "* Usamos **adstock+saturaci√≥n para construir (w)** y EM reparte sobre esa se√±al efectiva.\n",
        "\n",
        "Dime y genero el notebook del caso MMM‚ÜíMTA con mock data (impresiones/GRPs + transforms).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2849137c",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EM para desagregar contribuciones incrementales de MMM a MTA (campa√±as/creatividades)\n",
        "\n",
        "Este notebook muestra un enfoque **top-down**:\n",
        "\n",
        "- Un MMM produce contribuciones incrementales por **canal/medio** a nivel **tiempo** (y opcionalmente **geo**):  \n",
        "  \\( C_{m,t,g}^{inc} \\)\n",
        "\n",
        "- Queremos repartir \\( C_{m,t,g}^{inc} \\) a niveles inferiores (campa√±as/creas) \\(k\\) dentro del medio \\(m\\):  \n",
        "  \\( z_{m,k,t,g} \\), con la restricci√≥n:  \n",
        "  \\( \\sum_k z_{m,k,t,g} = C_{m,t,g}^{inc} \\)\n",
        "\n",
        "- Usamos como ‚Äúexposici√≥n‚Äù una se√±al de delivery (impresiones/GRPs) **transformada como en MMM**:\n",
        "  - **Adstock** (carryover)\n",
        "  - **Saturaci√≥n** (rendimientos decrecientes, p. ej. Hill)\n",
        "\n",
        "El reparto (E-step) se hace proporcional a:\n",
        "\\[\n",
        "\\lambda_{m,k}\\;\\cdot\\; s(\\text{Adstock}(x_{m,k,t,g}))\n",
        "\\]\n",
        "donde \\(x\\) son impresiones/GRPs y \\(s(\\cdot)\\) es saturaci√≥n.\n",
        "\n",
        "> Nota causal: si el MMM es incremental/causal a nivel canal, el total \\(C^{inc}\\) lo es.  \n",
        "> El split intra-canal es **atribuci√≥n model-based**, no causal garantizado, salvo que haya identificaci√≥n adicional intra-canal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Utilidades: Adstock y Saturaci√≥n (Hill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>adstock</th>\n",
              "      <th>sat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.283160e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.000</td>\n",
              "      <td>5.665459e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.000</td>\n",
              "      <td>4.145424e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>2.772369e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>7.160</td>\n",
              "      <td>4.667696e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.296</td>\n",
              "      <td>3.216698e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      x  adstock           sat\n",
              "0   0.0    0.000  3.283160e-16\n",
              "1  10.0   10.000  5.665459e-01\n",
              "2   0.0    6.000  4.145424e-01\n",
              "3   0.0    3.600  2.772369e-01\n",
              "4   5.0    7.160  4.667696e-01\n",
              "5   0.0    4.296  3.216698e-01"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def adstock_geometric(x, theta):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    a = np.zeros_like(x)\n",
        "    for t in range(len(x)):\n",
        "        a[t] = x[t] + (theta * a[t-1] if t > 0 else 0.0)\n",
        "    return a\n",
        "\n",
        "def hill_saturation(x, alpha, gamma):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x_pos = np.clip(x, 0.0, None)\n",
        "    xa = np.power(x_pos + 1e-12, alpha)\n",
        "    ga = np.power(gamma + 1e-12, alpha)\n",
        "    return xa / (xa + ga)\n",
        "\n",
        "def effective_exposure(x, theta, alpha, gamma):\n",
        "    a = adstock_geometric(x, theta=theta)\n",
        "    s = hill_saturation(a, alpha=alpha, gamma=gamma)\n",
        "    return a, s\n",
        "\n",
        "x = np.array([0, 10, 0, 0, 5, 0], dtype=float)\n",
        "a, s = effective_exposure(x, theta=0.6, alpha=1.2, gamma=8.0)\n",
        "pd.DataFrame({\"x\": x, \"adstock\": a, \"sat\": s})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Datos mock: canal (medio) -> campa√±as, con tiempo x geo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medium</th>\n",
              "      <th>campaign</th>\n",
              "      <th>geo</th>\n",
              "      <th>t</th>\n",
              "      <th>x_raw</th>\n",
              "      <th>x_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>G1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>G1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.642698</td>\n",
              "      <td>1.932004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>G1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>G1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.318439</td>\n",
              "      <td>1.694947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>G1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.183659</td>\n",
              "      <td>1.596413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   medium   campaign geo  t     x_raw  x_scaled\n",
              "0  Search  Search_C1  G1  0  0.000000  0.000000\n",
              "1  Search  Search_C1  G1  1  2.642698  1.932004\n",
              "2  Search  Search_C1  G1  2  0.000000  0.000000\n",
              "3  Search  Search_C1  G1  3  2.318439  1.694947\n",
              "4  Search  Search_C1  G1  4  2.183659  1.596413"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "M = 2\n",
        "K_per_m = 6\n",
        "T = 52\n",
        "G = 5\n",
        "\n",
        "media_names = [\"Search\", \"Social\"]\n",
        "geos = [f\"G{i+1}\" for i in range(G)]\n",
        "weeks = np.arange(T)\n",
        "\n",
        "theta_m = {\"Search\": 0.40, \"Social\": 0.65}\n",
        "alpha_m = {\"Search\": 1.20, \"Social\": 1.40}\n",
        "gamma_m = {\"Search\": 0.35, \"Social\": 0.25}\n",
        "\n",
        "campaign_rows = []\n",
        "for m in media_names:\n",
        "    for k in range(K_per_m):\n",
        "        campaign_rows.append({\n",
        "            \"medium\": m,\n",
        "            \"campaign\": f\"{m}_C{k+1}\",\n",
        "            \"creative_family\": rng.choice([\"A\", \"B\", \"C\"]),\n",
        "            \"objective\": rng.choice([\"Awareness\", \"Consideration\", \"Conversion\"], p=[0.3,0.4,0.3]),\n",
        "        })\n",
        "campaign_df = pd.DataFrame(campaign_rows)\n",
        "\n",
        "geo_effect = rng.lognormal(mean=0.0, sigma=0.25, size=G)\n",
        "time_season = 1.0 + 0.25*np.sin(2*np.pi*weeks/T) + 0.10*np.sin(4*np.pi*weeks/T)\n",
        "\n",
        "x_rows = []\n",
        "for _, row in campaign_df.iterrows():\n",
        "    m = row[\"medium\"]\n",
        "    k = row[\"campaign\"]\n",
        "    base = rng.lognormal(mean=0.0, sigma=0.5)\n",
        "    for g_idx, g in enumerate(geos):\n",
        "        level = base * geo_effect[g_idx] * rng.lognormal(mean=0.0, sigma=0.15)\n",
        "        x_t = level * time_season * rng.lognormal(mean=0.0, sigma=0.25, size=T)\n",
        "        mask = rng.random(T) < 0.08\n",
        "        x_t[mask] = 0.0\n",
        "        for t in range(T):\n",
        "            x_rows.append({\"medium\": m, \"campaign\": k, \"geo\": g, \"t\": int(t), \"x_raw\": float(x_t[t])})\n",
        "\n",
        "x_df = pd.DataFrame(x_rows)\n",
        "\n",
        "# Scale per medium to stabilize Hill gamma interpretation\n",
        "x_df[\"x_scaled\"] = x_df[\"x_raw\"]\n",
        "for m in media_names:\n",
        "    med = np.median(x_df.loc[(x_df.medium==m) & (x_df.x_raw>0), \"x_raw\"])\n",
        "    x_df.loc[x_df.medium==m, \"x_scaled\"] = x_df.loc[x_df.medium==m, \"x_raw\"] / (med + 1e-12)\n",
        "\n",
        "x_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Ground truth: productividad intra-medio y generaci√≥n de contribuciones incrementales del MMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   medium   campaign geo  t   adstock         s_eff  lambda_true  \\\n",
              " 0  Search  Search_C1  G1  0  0.000000  1.403196e-14     0.651796   \n",
              " 1  Search  Search_C1  G1  1  1.932004  8.859533e-01     0.651796   \n",
              " 2  Search  Search_C1  G1  2  0.772802  7.212172e-01     0.651796   \n",
              " 3  Search  Search_C1  G1  3  2.004068  8.903188e-01     0.651796   \n",
              " 4  Search  Search_C1  G1  4  2.398040  9.096500e-01     0.651796   \n",
              " \n",
              "              mu       C_inc    share_true        z_true  \n",
              " 0  9.145973e-15  378.395205  2.995334e-15  1.133420e-12  \n",
              " 1  5.774606e-01  514.354737  1.294276e-01  6.657172e+01  \n",
              " 2  4.700863e-01  489.302685  9.745898e-02  4.768694e+01  \n",
              " 3  5.803060e-01  421.869227  1.171586e-01  4.942560e+01  \n",
              " 4  5.929060e-01  555.417946  1.180323e-01  6.555724e+01  ,\n",
              "    medium  t geo       C_inc\n",
              " 0  Search  0  G1  378.395205\n",
              " 1  Search  1  G1  514.354737\n",
              " 2  Search  2  G1  489.302685\n",
              " 3  Search  3  G1  421.869227\n",
              " 4  Search  4  G1  555.417946,\n",
              "    medium   campaign creative_family   objective  lambda_true\n",
              " 0  Search  Search_C1               A   Awareness     0.651796\n",
              " 1  Search  Search_C2               C   Awareness     0.968844\n",
              " 2  Search  Search_C3               A   Awareness     0.478790\n",
              " 3  Search  Search_C4               A  Conversion     1.374762\n",
              " 4  Search  Search_C5               B   Awareness     1.654088)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "lambda_true = {}\n",
        "for m in media_names:\n",
        "    lam = rng.lognormal(mean=0.0, sigma=0.6, size=K_per_m)\n",
        "    lam = lam / lam.mean()\n",
        "    camps = campaign_df.loc[campaign_df.medium==m, \"campaign\"].tolist()\n",
        "    for i, k in enumerate(camps):\n",
        "        lambda_true[(m, k)] = float(lam[i])\n",
        "\n",
        "campaign_df[\"lambda_true\"] = campaign_df.apply(lambda r: lambda_true[(r[\"medium\"], r[\"campaign\"])], axis=1)\n",
        "\n",
        "# Effective exposure per (medium,campaign,geo) along time\n",
        "s_rows = []\n",
        "for (m,k,g), grp in x_df.groupby([\"medium\",\"campaign\",\"geo\"], sort=False):\n",
        "    grp = grp.sort_values(\"t\")\n",
        "    x = grp[\"x_scaled\"].to_numpy()\n",
        "    a, s = effective_exposure(x, theta=theta_m[m], alpha=alpha_m[m], gamma=gamma_m[m])\n",
        "    out = grp[[\"medium\",\"campaign\",\"geo\",\"t\"]].copy()\n",
        "    out[\"adstock\"] = a\n",
        "    out[\"s_eff\"] = s\n",
        "    s_rows.append(out)\n",
        "s_df = pd.concat(s_rows, ignore_index=True)\n",
        "\n",
        "beta_m = {\"Search\": 120.0, \"Social\": 80.0}\n",
        "\n",
        "sig = s_df.merge(campaign_df[[\"medium\",\"campaign\",\"lambda_true\"]], on=[\"medium\",\"campaign\"], how=\"left\")\n",
        "sig[\"mu\"] = sig[\"lambda_true\"] * sig[\"s_eff\"]\n",
        "\n",
        "C_rows = []\n",
        "for (m,t,g), grp in sig.groupby([\"medium\",\"t\",\"geo\"], sort=False):\n",
        "    total_mu = grp[\"mu\"].sum()\n",
        "    mean = beta_m[m] * total_mu\n",
        "    shape = 20.0\n",
        "    scale = (mean / shape) if mean > 0 else 0.0\n",
        "    C = float(rng.gamma(shape=shape, scale=scale)) if mean > 0 else 0.0\n",
        "    C_rows.append({\"medium\": m, \"t\": int(t), \"geo\": g, \"C_inc\": C})\n",
        "C_df = pd.DataFrame(C_rows)\n",
        "\n",
        "sig2 = sig.merge(C_df, on=[\"medium\",\"t\",\"geo\"], how=\"left\")\n",
        "sig2[\"share_true\"] = sig2[\"mu\"] / (sig2.groupby([\"medium\",\"t\",\"geo\"])[\"mu\"].transform(\"sum\") + 1e-12)\n",
        "sig2[\"z_true\"] = sig2[\"C_inc\"] * sig2[\"share_true\"]\n",
        "\n",
        "sig2.head(), C_df.head(), campaign_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) EM para desagregar C_inc a campa√±as (sin covariables): ecuaciones cerradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13429/2429345959.py:15: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
            "  tg = pd.factorize(list(zip(df[\"t\"], df[\"geo\"])))[0].astype(int)\n",
            "/tmp/ipykernel_13429/2429345959.py:15: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
            "  tg = pd.factorize(list(zip(df[\"t\"], df[\"geo\"])))[0].astype(int)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(    campaign  lambda_hat  medium\n",
              " 0  Search_C1    1.061351  Search\n",
              " 1  Search_C2    0.604222  Search\n",
              " 2  Search_C3    0.718040  Search\n",
              " 3  Search_C4    1.437445  Search\n",
              " 4  Search_C5    1.313828  Search,\n",
              "     campaign  t geo         s_eff       C_inc          zhat  medium\n",
              " 0  Search_C1  0  G1  1.403196e-14  378.395205  2.161738e-12  Search\n",
              " 1  Search_C1  1  G1  8.859533e-01  514.354737  1.066937e+02  Search\n",
              " 2  Search_C1  2  G1  7.212172e-01  489.302685  7.821551e+01  Search\n",
              " 3  Search_C1  3  G1  8.903188e-01  421.869227  7.988590e+01  Search\n",
              " 4  Search_C1  4  G1  9.096500e-01  555.417946  1.059257e+02  Search)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def em_mmm_to_mta_single_medium(sig_m, C_m, max_iter=200, tol=1e-8, verbose=True):\n",
        "    df = sig_m.merge(C_m, on=[\"t\",\"geo\"], how=\"left\")\n",
        "    df[\"C_inc\"] = df[\"C_inc\"].fillna(0.0)\n",
        "\n",
        "    campaigns = df[\"campaign\"].unique().tolist()\n",
        "    K = len(campaigns)\n",
        "    camp_to_idx = {c:i for i,c in enumerate(campaigns)}\n",
        "\n",
        "    k_idx = df[\"campaign\"].map(camp_to_idx).to_numpy().astype(int)\n",
        "    s = df[\"s_eff\"].to_numpy().astype(float)\n",
        "\n",
        "    tg = pd.factorize(list(zip(df[\"t\"], df[\"geo\"])))[0].astype(int)\n",
        "    C = df[\"C_inc\"].to_numpy().astype(float)\n",
        "\n",
        "    n_groups = int(tg.max()) + 1\n",
        "\n",
        "    lambda_hat = np.ones(K, dtype=float)\n",
        "    history = {\"rel_change\": []}\n",
        "\n",
        "    s_sum_k = np.bincount(k_idx, weights=s, minlength=K) + 1e-12\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        num = lambda_hat[k_idx] * s\n",
        "        den_g = np.bincount(tg, weights=num, minlength=n_groups) + 1e-12\n",
        "        share = num / den_g[tg]\n",
        "        zhat = C * share\n",
        "\n",
        "        z_sum_k = np.bincount(k_idx, weights=zhat, minlength=K)\n",
        "        lambda_new = z_sum_k / s_sum_k\n",
        "\n",
        "        # normalize scale within medium (optional)\n",
        "        lambda_new = lambda_new / (lambda_new.mean() + 1e-12)\n",
        "\n",
        "        rel = float(np.linalg.norm(lambda_new - lambda_hat) / (np.linalg.norm(lambda_hat) + 1e-12))\n",
        "        history[\"rel_change\"].append(rel)\n",
        "\n",
        "        if verbose and (it < 5 or it % 20 == 0):\n",
        "            print(f\"iter {it:3d} | rel_change={rel: .3e}\")\n",
        "\n",
        "        lambda_hat = lambda_new\n",
        "        if rel < tol:\n",
        "            break\n",
        "\n",
        "    df_out = df[[\"campaign\",\"t\",\"geo\",\"s_eff\",\"C_inc\"]].copy()\n",
        "    df_out[\"zhat\"] = zhat\n",
        "    return pd.Series(lambda_hat, index=campaigns, name=\"lambda_hat\"), df_out, history\n",
        "\n",
        "results = []\n",
        "lambda_hats = []\n",
        "histories = {}\n",
        "\n",
        "for m in media_names:\n",
        "    sig_m = sig2.loc[sig2.medium==m, [\"campaign\",\"t\",\"geo\",\"s_eff\"]].copy()\n",
        "    C_m = C_df.loc[C_df.medium==m, [\"t\",\"geo\",\"C_inc\"]].copy()\n",
        "\n",
        "    lam_hat, df_hat, hist = em_mmm_to_mta_single_medium(sig_m, C_m, verbose=False)\n",
        "    df_hat[\"medium\"] = m\n",
        "    results.append(df_hat)\n",
        "\n",
        "    lam_hat_df = lam_hat.reset_index().rename(columns={\"index\":\"campaign\"})\n",
        "    lam_hat_df[\"medium\"] = m\n",
        "    lambda_hats.append(lam_hat_df)\n",
        "\n",
        "    histories[m] = hist\n",
        "\n",
        "zhat_df = pd.concat(results, ignore_index=True)\n",
        "lambda_hat_df = pd.concat(lambda_hats, ignore_index=True)\n",
        "\n",
        "lambda_hat_df.head(), zhat_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Checks y evaluaci√≥n (ground truth disponible en mock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max |gap| = 2.1509549696929753e-10\n",
            "corr(lambda_true, lambda_hat) por medio:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13429/1912274994.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  corr_lam = lam_cmp.groupby(\"medium\").apply(lambda d: np.corrcoef(d[\"lambda_true\"], d[\"lambda_hat\"])[0,1])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "medium\n",
              "Search    0.716181\n",
              "Social    0.484505\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medium</th>\n",
              "      <th>campaign</th>\n",
              "      <th>lambda_true</th>\n",
              "      <th>lambda_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C1</td>\n",
              "      <td>0.651796</td>\n",
              "      <td>1.061351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C2</td>\n",
              "      <td>0.968844</td>\n",
              "      <td>0.604222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C3</td>\n",
              "      <td>0.478790</td>\n",
              "      <td>0.718040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C4</td>\n",
              "      <td>1.374762</td>\n",
              "      <td>1.437445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Search</td>\n",
              "      <td>Search_C5</td>\n",
              "      <td>1.654088</td>\n",
              "      <td>1.313828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   medium   campaign  lambda_true  lambda_hat\n",
              "0  Search  Search_C1     0.651796    1.061351\n",
              "1  Search  Search_C2     0.968844    0.604222\n",
              "2  Search  Search_C3     0.478790    0.718040\n",
              "3  Search  Search_C4     1.374762    1.437445\n",
              "4  Search  Search_C5     1.654088    1.313828"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "chk = (zhat_df.groupby([\"medium\",\"t\",\"geo\"])[\"zhat\"].sum()\n",
        "       .reset_index()\n",
        "       .merge(C_df, on=[\"medium\",\"t\",\"geo\"], how=\"left\"))\n",
        "chk[\"gap\"] = chk[\"zhat\"] - chk[\"C_inc\"]\n",
        "print(\"max |gap| =\", float(chk[\"gap\"].abs().max()))\n",
        "\n",
        "lam_true_df = campaign_df[[\"medium\",\"campaign\",\"lambda_true\"]].copy()\n",
        "lam_cmp = lam_true_df.merge(lambda_hat_df, on=[\"medium\",\"campaign\"], how=\"left\")\n",
        "\n",
        "corr_lam = lam_cmp.groupby(\"medium\").apply(lambda d: np.corrcoef(d[\"lambda_true\"], d[\"lambda_hat\"])[0,1])\n",
        "print(\"corr(lambda_true, lambda_hat) por medio:\")\n",
        "display(corr_lam)\n",
        "\n",
        "lam_cmp.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search | corr(z_true, zhat) = 0.7002968124473625 | rmse = 28.332376353147925\n",
            "Social | corr(z_true, zhat) = 0.3973770228289043 | rmse = 68.3273734856492\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "z_cmp = (sig2[[\"medium\",\"campaign\",\"t\",\"geo\",\"z_true\"]]\n",
        "         .merge(zhat_df[[\"medium\",\"campaign\",\"t\",\"geo\",\"zhat\"]], on=[\"medium\",\"campaign\",\"t\",\"geo\"], how=\"left\"))\n",
        "\n",
        "for m in media_names:\n",
        "    d = z_cmp.loc[z_cmp.medium==m]\n",
        "    corr = np.corrcoef(d[\"z_true\"], d[\"zhat\"])[0,1]\n",
        "    rmse = float(np.sqrt(np.mean((d[\"z_true\"] - d[\"zhat\"])**2)))\n",
        "    print(m, \"| corr(z_true, zhat) =\", corr, \"| rmse =\", rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) D√≥nde entra adstock + saturaci√≥n (resumen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "En este enfoque, adstock + saturaci√≥n se usan para construir la exposici√≥n efectiva:\n",
        "\n",
        "\\[\n",
        "w_{m,k,t,g} := s_{m,k,t,g} = \\text{Hill}(\\text{Adstock}(x_{m,k,t,g}))\n",
        "\\]\n",
        "\n",
        "y luego el E-step reparte:\n",
        "\n",
        "\\[\n",
        "\\hat z_{m,k,t,g} = C_{m,t,g}^{inc} \\cdot\n",
        "\\frac{\\lambda_{m,k} w_{m,k,t,g}}\n",
        "{\\sum_{k'} \\lambda_{m,k'} w_{m,k',t,g}}\n",
        "\\]\n",
        "\n",
        "Esto respeta la estructura MMM y conserva masa: \\(\\sum_k \\hat z = C\\).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Opcional) Extensi√≥n a features por campa√±a (lambda = exp(X beta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Si quieres generalizar / regularizar:\n",
        "\n",
        "\\[\n",
        "\\lambda_{m,k} = \\exp(X_{m,k} \\beta_m)\n",
        "\\]\n",
        "\n",
        "El M-step pasa a ser un GLM (Poisson/Gamma) con offset (igual que HCP‚ÄìBrick).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Granularidad horaria (para m√°s adelante)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Si el MMM est√° a nivel semanal/diario pero necesitas atribuci√≥n horaria:\n",
        "\n",
        "1) Ejecutas EM a nivel (t,g) y obtienes \\(\\hat z_{m,k,t,g}\\)\n",
        "2) Downscaling horario con perfil de delivery y conservaci√≥n de masa:\n",
        "\n",
        "\\[\n",
        "\\hat z_{m,k,t,g,h} = \\hat z_{m,k,t,g} \\cdot\n",
        "\\frac{u_{m,k,t,g,h}}{\\sum_h u_{m,k,t,g,h}}\n",
        "\\]\n",
        "\n",
        "donde \\(u\\) puede ser impresiones horarias o un modelo de intensidad suavizado.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
